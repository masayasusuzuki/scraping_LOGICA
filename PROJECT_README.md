# 多目的 求人サイトスクレイピング・ダッシュボード

## 📋 プロジェクト概要

複数の求人サイトから効率的に求人情報を収集するためのStreamlitベースのダッシュボードアプリケーションです。
現在は「メディカル・コンシェルジュネット」に対応しています。

## 🚀 セットアップ方法

### 1. 依存関係のインストール

```bash
pip install -r requirements.txt
```

### 2. アプリケーションの起動

```bash
streamlit run app.py
```

ブラウザで `http://localhost:8501` にアクセスしてアプリケーションを使用してください。

## 🎯 機能

### ✅ 実装済み機能

- **ダッシュボードUI**: サイドバーでのサイト選択と動的UI切り替え
- **メディカル・コンシェルジュネット対応**:
  - 動的な検索条件取得（職種、働き方、都道府県、施設区分）
  - フリーワード検索
  - 全ページの自動巡回
  - データ抽出とCSV出力
- **結果表示**: データテーブル、統計情報、CSVダウンロード
- **エラーハンドリング**: ネットワークエラーやサイト構造変更への対応
- **サーバー配慮**: リクエスト間の適切な待機時間

### 📊 抽出データ項目

- 求人No
- タイトル
- 職種
- 勤務地
- 施設
- 業務 (働き方)
- 給与
- 交通
- 詳細ページURL
- 情報源サイト名

## 🏗️ プロジェクト構造

```
scrapingapplication/
├── app.py                          # メインアプリケーション
├── requirements.txt                # 依存関係
├── scrapers/                       # スクレイピングモジュール
│   ├── __init__.py
│   └── medical_concierge.py        # メディカル・コンシェルジュネット専用モジュール
├── README.md                       # 元の要件定義書
└── PROJECT_README.md               # このファイル
```

## 🔧 技術仕様

- **フレームワーク**: Python, Streamlit
- **スクレイピング**: requests, BeautifulSoup
- **データ処理**: pandas
- **文字コード**: Shift_JIS対応
- **HTTPセッション**: requests.Session使用
- **パフォーマンス**: 適切な待機時間とページネーション

## 📝 使用方法

1. アプリケーションを起動後、サイドバーで「メディカル・コンシェルジュネット」を選択
2. 検索条件を設定:
   - 職種、働き方、都道府県、施設区分をプルダウンから選択
   - 必要に応じてフリーワードを入力
3. 「この条件で検索する」ボタンをクリック
4. 結果を確認し、必要に応じてCSVファイルをダウンロード

## ⚠️ 注意事項

- サーバーに負荷をかけないよう、リクエスト間に2秒の待機時間を設けています
- ネットワークエラーやサイト構造変更でエラーが発生する場合があります
- 大量のデータ取得には時間がかかる場合があります

## 🔮 将来の拡張予定

- 他の求人サイトへの対応
- より高度な検索フィルタリング
- データ分析機能
- 自動更新機能

## 🛠️ トラブルシューティング

### よくある問題

1. **検索条件が読み込まれない**
   - ネットワーク接続を確認してください
   - 「検索条件を再読み込み」ボタンをクリックしてください

2. **スクレイピングでエラーが発生する**
   - 対象サイトのメンテナンスやアクセス制限の可能性があります
   - しばらく時間をおいてから再試行してください

3. **CSVファイルの文字化け**
   - UTF-8-BOM形式で出力しているため、Excelで正常に表示されるはずです
   - 他のツールで開く場合は文字コード設定を確認してください

## 📄 ライセンス

このプロジェクトは要件定義書に基づいて作成されており、教育・研究目的での使用を想定しています。
商用利用の際は、対象サイトの利用規約を十分に確認してください。 