### 1. プロジェクト概要

| 項目 | 内容 |
| :--- | :--- |
| **1.1. ツール名称** | 多目的 求人サイトスクレイピング・ダッシュボード |
| **1.2. 目的** | 複数の求人サイトから、それぞれのサイトに最適化されたUIを通じて求人情報を効率的に収集し、データとして活用可能にすること。 |
| **1.3. ツールコンセプト** | サイドバーで対象サイトを選択すると、メイン画面のUIがそのサイト専用の検索画面に切り替わるダッシュボード形式。 |
| **1.4. 開発フレームワーク**| Python, Streamlit |
| **1.5. 当面の開発スコープ**| **フェーズ1**: 「メディカル・コンシェルジュネット」のUIとスクレイピング機能を完璧に実装する。<br>**フェーズ2**: 「美容ナース.com」を追加し、複数サイト対応の基盤を確立する。 |

---
### 2. 機能要件

#### 2.1. 全体UI構造（ダッシュボード共通）
どのサイトを選択しても共通となる、アプリケーションの基本的な骨格に関する要件。

| No. | 機能名 | 機能概要 |
|:---:|:---|:---|
| 2.1.1 | **サイト選択サイドバー** | 画面左側のサイドバーに、対象となる求人サイトのリストをラジオボタン形式で表示する。ユーザーはここから操作対象のサイトを選択する。 |
| 2.1.2 | **動的UI表示エリア** | メイン画面のエリア。サイドバーでのサイト選択に応じて、後述の「2.2. サイト別UI定義」で定められた専用UIに内容が完全に切り替わる。 |
| 2.1.3 | **結果表示エリア** | スクレイピング実行後、メイン画面の下部に取得結果を表示する共通エリア。以下の要素を含む。<br>・**取得件数:** `st.success`等で「〇〇件の求人が見つかりました。」と表示。<br>・**結果データテーブル:** `st.dataframe`で取得データを表示。<br>・**CSVダウンロードボタン:** `st.download_button`で結果をCSV出力。 |

#### 2.2. サイト別UI定義
サイドバーの選択に応じて、メイン画面の「動的UI表示エリア」に表示される、各サイト専用のインターフェース定義。

| No. | 対象サイト | UI仕様 |
|:---:|:---|:---|
| **2.2.1** | **メディカル・コンシェルジュネット** | **以下のコンポーネントを上から順に配置する。**<br><br>**■ 見出し**<br>・大見出しとして「`メディカル・コンシェルジュネット：検索条件`」を表示する。<br><br>**■ 検索条件入力部**<br>・2カラムレイアウトで入力項目を配置する。<br>  - **左カラム:**<br>    1. `職種`：プルダウン (`st.selectbox`)<br>    2. `働き方`：プルダウン (`st.selectbox`)<br>  - **右カラム:**<br>    1. `都道府県`：プルダウン (`st.selectbox`)<br>    2. `施設区分`：プルダウン (`st.selectbox`)<br><br>**■ フリーワード入力部**<br>・上記カラムの下に「`フリーワード`」のラベルを持つ一行テキストボックス (`st.text_input`) を配置する。<br><br>**■ 実行部**<br>・最下部に「`この条件で検索する`」というラベルのボタン (`st.button`) を配置する。<br><br>*(補足: 各プルダウンの選択肢は、対象サイトのHTMLから動的に取得したものを表示する)*|
| **2.2.2** | **美容ナース.com** | **以下のコンポーネントを上から順に配置する。**<br><br>**■ 見出し**<br>・大見出しとして「`美容ナース.com：検索条件`」を表示する。<br><br>**■ 検索条件入力部**<br>・3カラムレイアウトで入力項目を配置する。<br>  - **左カラム (エリア):**<br>    1. `都道府県`：プルダウン (`st.selectbox`)<br>  - **中央カラム (給料):**<br>    1. `給料を選択`：プルダウン (`st.selectbox`)<br>  - **右カラム (ご希望の診療科目):**<br>    1. `美容外科`：チェックボックス (`st.checkbox`)<br>    2. `美容皮膚科`：チェックボックス (`st.checkbox`)<br><br>**■ クリニック名入力部**<br>・上記カラムの下に「`クリニック名`」のラベルを持つ一行テキストボックス (`st.text_input`) を配置する。<br><br>**■ 実行部**<br>・最下部に「`求人を探す`」というラベルのボタン (`st.button`) を配置する。<br><br>*(補足: 都道府県と給料の選択肢は、対象サイトのHTMLから動的に取得したものを表示する)*|

---
### 3. データ要件（抽出項目）
| No. | 項目名 | データ型 | 備考 |
|:---:|:---|:---|:---|
| 3.1 | **求人No** | 文字列 | 案件を特定する一意のID。 |
| 3.2 | **タイトル** | 文字列 | 求人案件のタイトル。 |
| 3.3 | **職種** | 文字列 | |
| 3.4 | **勤務地** | 文字列 | |
| 3.5 | **施設** | 文字列 | |
| 3.6 | **業務 (働き方)** | 文字列 | |
| 3.7 | **給与** | 文字列 | 「(続く)」の部分も含め、取得できるテキストをそのまま格納する。 |
| 3.8 | **交通** | 文字列 | |
| 3.9 | **詳細ページURL** | 文字列 | |
| 3.10 | **情報源サイト名** | 文字列 | どのサイトからの情報か識別するため。「メディカル・コンシェルジュネット」「美容ナース.com」等のサイト名を格納。 |

---
### 4. 非機能要件
システムの品質や制約に関する要件。

| No. | 要件名 | 内容 |
|:---:|:---|:---|
| 4.1 | **パフォーマンス** | 検索条件確定後、ユーザーが待てる現実的な時間内（数分以内を目標）に結果を表示する。 |
| 4.2 | **信頼性・堅牢性** | - **サーバーへの配慮**: サイトに過度な負荷をかけないよう、リクエストごとに1〜3秒の待機時間 (`time.sleep`) を設ける。<br>- **エラーハンドリング**: ネットワークエラーやサイトの構造変更で情報が取得できない場合、処理を安全に停止し、エラーメッセージをユーザーに通知する。 |
| 4.3 | **保守性** | - **コードの可読性**: 関数や変数の命名を分かりやすくし、コメントを適切に記述する。<br>- **設定の分離**: URLやCSSセレクタなどの変更されやすい値は、コードの先頭部分で定数として管理し、変更を容易にする。 |

---
### 5. 開発アーキテクチャ方針

| 項目 | 方針 |
|:--- |:---|
| **5.1. モジュール性** | サイトごとのロジックを完全に分離する。<br>・`app.py`：UIの切り替え制御と全体レイアウトのみ担当。<br>・`scrapers/`フォルダ：サイト別の処理を格納。<br>・`scrapers/medical_concierge.py`：**UI生成とスクレイピング実行の両方を担う**、メディカルコンシェルジュ専用モジュール。<br>・`scrapers/biyou_nurse.py`：**UI生成とスクレイピング実行の両方を担う**、美容ナース.com専用モジュール。 |
| **5.2. 開発フェーズ** | **フェーズ1**: 基盤（`app.py`の枠組み）と`medical_concierge.py`の実装に集中する。<br>**フェーズ2**: 「美容ナース.com」用の`scrapers/biyou_nurse.py`を追加開発し、複数サイト対応の基盤を確立する。この段階で他のサイト追加のためのテンプレートが完成する。 |
| **5.3. スクレイピング技術**| **メディカル・コンシェルジュネット**:<br>- **対象サイトURL**: `https://www.concier.net/jobs/search/`<br>- **文字コード**: `shift_jis`に対応<br>- **検索方式**: HTTP POSTリクエストを再現<br>- **ページネーション**: `requests.Session`オブジェクトを利用してセッションを維持し、次ページURLへGETリクエスト<br><br>**美容ナース.com**:<br>- **対象サイトURL**: `https://biyou-nurse.com/search/`<br>- **文字コード**: `UTF-8`<br>- **検索方式**: HTTP GETリクエスト<br>- **ページネーション**: JavaScript制御のため、URLパラメータ (`&page=2`など) でのアクセスを試行 |
| **5.4. 使用ライブラリ** | - `streamlit`: UI構築<br>- `requests`: HTTP通信<br>- `beautifulsoup4`: HTML解析<br>- `pandas`: データ整形・CSV出力<br>- `lxml`: `beautifulsoup4`用の高速パーサー |

################################################################################
#
# 実装における技術的な注意点
#
################################################################################

## メディカル・コンシェルジュネットにおける注意点

### 1. 検索リクエストの再現（最重要）

-   **方式**: `<form action="/jobs/search" method="post">` より、**HTTP POSTリクエスト**を使用する。
-   **送信先URL**: `https://www.concier.net/jobs/search`
-   **送信データ（ペイロード）**: UIで選択された条件を、`<input>`や`<select>`の`name`属性と`value`属性のペアからなる辞書として作成し、`requests.post()`の`data`引数に渡す。
    -   例: `payload = {'jobId': 'oth_010121', 'localId': '12', ...}`

### 2. 文字コードの取り扱い

-   **指定**: `<meta ... charset=shift_jis" />` より、文字コードは **Shift_JIS**。
-   **対策**: `requests`で取得した`response`オブジェクトに対し、`response.encoding = 'shift_jis'` または `response.encoding = response.apparent_encoding` を設定してから `.text` プロパティにアクセスし、文字化けを防ぐ。

### 3. ページネーション（複数ページの巡回）

-   **仕組み**: このサイトはPOST検索の結果をサーバー側セッションで保持している。
-   **対策**: `requests.Session()` を使用する。
    1.  `session = requests.Session()` でセッションを開始する。
    2.  初回の検索は `session.post()` で実行する。
    3.  検索結果ページから次ページへのリンク（例: `/jobs/search/.../page~2`）を抽出し、`session.get()` でアクセスする。これによりCookieが引き継がれ、検索状態が維持される。
    4.  次ページへのリンクがなくなるまで、3の処理をループする。

### 4. データ抽出のためのCSSセレクタ戦略

-   **全案件ブロック**: `div.job-dtl-itm`
-   **項目別抽出 (各ブロック内)**:
    -   **求人No**: `div.job-dtl-no > p`
    -   **タイトル**: `div.job-dtl-ttl > h3`
    -   **詳細ページURL**: `div.job-dtl-btn > a.btn` (最初のaタグ) の `href` 属性。ベースURLとの結合を忘れないこと。
    -   **テーブルデータ**: `table.job-dtl-cont tr` で各行を取得後、行内の`th` (項目名)と`td` (値)を紐づけて辞書に格納する。項目の順序変動に強いロジックを組む。

### 5. 堅牢性の確保（エラーハンドリング）

-   **`try-except`構文**:
    -   個々のデータ抽出処理（`find`や`select`）を`try-except AttributeError`で囲み、特定のデータが存在しなくてもプログラムが停止しないようにする。見つからない場合は `None` や空文字を代入する。
    -   HTTPリクエスト（`session.post/get`）を`try-except requests.exceptions.RequestException`で囲み、ネットワークエラーを捕捉する。
-   **User-Agentの設定**: リクエストヘッダーにブラウザを偽装する`User-Agent`を設定し、ボット判定を回避する。
    -   `headers = {'User-Agent': 'Mozilla/5.0 ...'}`

### 6. サーバーへの配慮

-   **待機時間**: ループ処理内でページを取得するごとに `time.sleep(2)` のように2秒程度の待機時間を設ける。短時間での連続アクセスは絶対に避けること。

## 美容ナース.comにおける注意点

### 1. 検索リクエストの再現

-   **方式**: **HTTP GETリクエスト**を使用する。
-   **送信先URL**: `https://biyou-nurse.com/search/`
-   **パラメータ**: URLパラメータとして検索条件を付与する。
    -   例: `https://biyou-nurse.com/search/?prefecture=tokyo&salary=high&biyou_geka=1`

### 2. 文字コードの取り扱い

-   **指定**: 文字コードは **UTF-8**。
-   **対策**: `requests`のデフォルトエンコーディングで対応可能。

### 3. ページネーション（複数ページの巡回）

-   **仕組み**: JavaScript制御によるページネーション。
-   **対策**: URLパラメータ (`&page=2`, `&page=3`など) を追加してアクセスを試行する。
    1.  初回検索でベースURLにパラメータを付与してGETリクエスト。
    2.  次ページは `&page=2` を追加したURLで再度GETリクエスト。
    3.  404エラーまたは結果が0件になるまでページ番号を増やして継続。

### 4. データ抽出のためのCSSセレクタ戦略

-   **全案件ブロック**: `ul.list_jobs2 > li`
-   **項目別抽出 (各ブロック内)**:
    -   **タイトル**: `h2`タグ
    -   **クリニック名**: `p.clinick_name`
    -   **詳細ページURL**: `a`タグの`href`属性 (ベースURLとの結合が必要)
    -   **勤務地**: `span.cate`タグ
    -   **メインの施術**: `dl > dd`タグ

### 5. 堅牢性の確保（エラーハンドリング）

-   **`try-except`構文**: メディカル・コンシェルジュネットと同様の方針。
-   **User-Agentの設定**: 同様にブラウザを偽装する。

### 6. サーバーへの配慮

-   **待機時間**: ページ遷移ごとに `time.sleep(2)` で2秒以上の待機時間を設ける。# scraping_LOGICA
