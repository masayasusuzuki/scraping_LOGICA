import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import re
from urllib.parse import urljoin, urlencode

class BiyouNurseUI:
    """ç¾å®¹ãƒŠãƒ¼ã‚¹.comå°‚ç”¨ã®UIã¨ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æ©Ÿèƒ½"""
    
    # è¨­å®šå®šæ•°
    BASE_URL = "https://biyou-nurse.com"
    SEARCH_URL = "https://biyou-nurse.com/job/"
    
    # HTTPãƒ˜ãƒƒãƒ€ãƒ¼è¨­å®š
    HEADERS = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.session = requests.Session()
        self.session.headers.update(self.HEADERS)
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ–
        if 'biyou_search_options' not in st.session_state:
            st.session_state.biyou_search_options = {}
    
    def get_search_options(self):
        """æ¤œç´¢ãƒ•ã‚©ãƒ¼ãƒ ã®é¸æŠè‚¢ã‚’å‹•çš„ã«å–å¾—"""
        try:
            response = self.session.get(self.BASE_URL)
            response.encoding = 'utf-8'
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            options = {}
            
            # éƒ½é“åºœçœŒã®é¸æŠè‚¢ã‚’å–å¾—
            prefecture_select = soup.find('select', {'name': 'ken_cd'})
            if prefecture_select:
                prefecture_options = [(opt.get('value', ''), opt.get_text(strip=True)) 
                                    for opt in prefecture_select.find_all('option') if opt.get('value')]
                options['éƒ½é“åºœçœŒ'] = prefecture_options
            else:
                # HTMLã§è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸé¸æŠè‚¢ã‚’ä½¿ç”¨
                options['éƒ½é“åºœçœŒ'] = [
                    ('13', 'æ±äº¬éƒ½'), ('14', 'ç¥å¥ˆå·çœŒ'), ('11', 'åŸ¼ç‰çœŒ'), ('12', 'åƒè‘‰çœŒ'),
                    ('23', 'æ„›çŸ¥çœŒ'), ('27', 'å¤§é˜ªåºœ'), ('26', 'äº¬éƒ½åºœ'), ('28', 'å…µåº«çœŒ'),
                    ('40', 'ç¦å²¡çœŒ'), ('01', 'åŒ—æµ·é“'), ('02', 'é’æ£®çœŒ'), ('03', 'å²©æ‰‹çœŒ'),
                    ('04', 'å®®åŸçœŒ'), ('05', 'ç§‹ç”°çœŒ'), ('06', 'å±±å½¢çœŒ'), ('07', 'ç¦å³¶çœŒ'),
                    ('08', 'èŒ¨åŸçœŒ'), ('09', 'æ ƒæœ¨çœŒ'), ('10', 'ç¾¤é¦¬çœŒ'), ('15', 'æ–°æ½ŸçœŒ'),
                    ('16', 'å¯Œå±±çœŒ'), ('17', 'çŸ³å·çœŒ'), ('18', 'ç¦äº•çœŒ'), ('19', 'å±±æ¢¨çœŒ'),
                    ('20', 'é•·é‡çœŒ'), ('21', 'å²é˜œçœŒ'), ('22', 'é™å²¡çœŒ'), ('24', 'ä¸‰é‡çœŒ'),
                    ('25', 'æ»‹è³€çœŒ'), ('29', 'å¥ˆè‰¯çœŒ'), ('30', 'å’Œæ­Œå±±çœŒ'), ('31', 'é³¥å–çœŒ'),
                    ('32', 'å³¶æ ¹çœŒ'), ('33', 'å²¡å±±çœŒ'), ('34', 'åºƒå³¶çœŒ'), ('35', 'å±±å£çœŒ'),
                    ('36', 'å¾³å³¶çœŒ'), ('37', 'é¦™å·çœŒ'), ('38', 'æ„›åª›çœŒ'), ('39', 'é«˜çŸ¥çœŒ'),
                    ('41', 'ä½è³€çœŒ'), ('42', 'é•·å´çœŒ'), ('43', 'ç†Šæœ¬çœŒ'), ('44', 'å¤§åˆ†çœŒ'),
                    ('45', 'å®®å´çœŒ'), ('46', 'é¹¿å…å³¶çœŒ'), ('47', 'æ²–ç¸„çœŒ')
                ]
            
            # è³‡æ ¼ã®é¸æŠè‚¢ï¼ˆå®Ÿéš›ã®ã‚µã‚¤ãƒˆã‹ã‚‰ï¼‰
            options['è³‡æ ¼'] = [('1', 'æ­£çœ‹è­·å¸«'), ('0', 'å‡†çœ‹è­·å¸«')]
            
            return options
            
        except Exception as e:
            st.error(f"æ¤œç´¢ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”ã™
            return {
                'éƒ½é“åºœçœŒ': [
                    ('13', 'æ±äº¬éƒ½'), ('14', 'ç¥å¥ˆå·çœŒ'), ('11', 'åŸ¼ç‰çœŒ'), ('12', 'åƒè‘‰çœŒ'),
                    ('23', 'æ„›çŸ¥çœŒ'), ('27', 'å¤§é˜ªåºœ'), ('26', 'äº¬éƒ½åºœ'), ('28', 'å…µåº«çœŒ'),
                    ('40', 'ç¦å²¡çœŒ')
                ],
                'è³‡æ ¼': [('1', 'æ­£çœ‹è­·å¸«'), ('0', 'å‡†çœ‹è­·å¸«')]
            }
    
    def render_ui(self):
        """ç¾å®¹ãƒŠãƒ¼ã‚¹.comå°‚ç”¨ã®UIã‚’è¡¨ç¤º"""
        st.header("ç¾å®¹ãƒŠãƒ¼ã‚¹.comï¼šæ¤œç´¢æ¡ä»¶")
        
        # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰
        debug_mode = st.sidebar.checkbox("ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰", key="biyou_debug")
        
        # æ¤œç´¢ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰
        if not st.session_state.biyou_search_options:
            with st.spinner("æ¤œç´¢æ¡ä»¶ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
                st.session_state.biyou_search_options = self.get_search_options()
        
        search_options = st.session_state.biyou_search_options
        
        if not search_options:
            st.error("æ¤œç´¢æ¡ä»¶ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚")
            if st.button("æ¤œç´¢æ¡ä»¶ã‚’å†èª­ã¿è¾¼ã¿", key="biyou_reload"):
                st.session_state.biyou_search_options = {}
                st.rerun()
            return None
        
        # æ¤œç´¢æ¡ä»¶å…¥åŠ›éƒ¨ï¼ˆ3ã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼‰
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # éƒ½é“åºœçœŒ
            prefecture_options = search_options.get('éƒ½é“åºœçœŒ', [])
            if prefecture_options:
                # å…ˆé ­ã«ã€Œå…¨ã¦ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
                prefecture_options_with_all = [('', 'éƒ½é“åºœçœŒã‚’é¸æŠ')] + prefecture_options
                prefecture_labels = [label for value, label in prefecture_options_with_all]
                prefecture_values = [value for value, label in prefecture_options_with_all]
                
                selected_prefecture_label = st.selectbox(
                    "éƒ½é“åºœçœŒ",
                    prefecture_labels,
                    index=0,
                    key="biyou_prefecture"
                )
                selected_prefecture_index = prefecture_labels.index(selected_prefecture_label)
                selected_prefecture = prefecture_values[selected_prefecture_index]
            else:
                st.error("éƒ½é“åºœçœŒã®é¸æŠè‚¢ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                selected_prefecture = ""
        
        with col2:
            # è³‡æ ¼
            license_options = search_options.get('è³‡æ ¼', [])
            if license_options:
                license_labels = [label for value, label in license_options]
                license_values = [value for value, label in license_options]
                
                selected_license_label = st.selectbox(
                    "ä¿æœ‰è³‡æ ¼",
                    license_labels,
                    index=0,
                    key="biyou_license"
                )
                selected_license_index = license_labels.index(selected_license_label)
                selected_license = license_values[selected_license_index]
            else:
                st.error("è³‡æ ¼ã®é¸æŠè‚¢ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                selected_license = "1"
        
        with col3:
            # ã”å¸Œæœ›ã®è¨ºç™‚ç§‘ç›®
            st.markdown("**ã”å¸Œæœ›ã®è¨ºç™‚ç§‘ç›®**")
            biyou_geka = st.checkbox("ç¾å®¹å¤–ç§‘", value=True, key="biyou_geka")
            biyou_hifuka = st.checkbox("ç¾å®¹çš®è†šç§‘", key="biyou_hifuka")
        
        # å–å¾—ä»¶æ•°é¸æŠ
        max_jobs = st.selectbox(
            "å–å¾—ä»¶æ•°ã‚’é¸æŠ",
            [10, 20, 50, 100],
            index=3,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§100ä»¶
            key="biyou_max_jobs",
            help="è©³ç´°æƒ…å ±ã‚’å«ã‚ã¦å–å¾—ã™ã‚‹æ±‚äººã®æœ€å¤§ä»¶æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„"
        )
        
        # è©³ç´°æƒ…å ±å–å¾—ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        get_details = st.checkbox(
            "è©³ç´°æƒ…å ±ã‚’å–å¾—ã™ã‚‹",
            value=True,
            key="biyou_get_details",
            help="å„æ±‚äººã®è©³ç´°ãƒšãƒ¼ã‚¸ã‹ã‚‰è¿½åŠ æƒ…å ±ã‚’å–å¾—ã—ã¾ã™ï¼ˆå‡¦ç†æ™‚é–“ãŒé•·ããªã‚Šã¾ã™ï¼‰"
        )
        
        # å®Ÿè¡Œéƒ¨
        if st.button("æ±‚äººã‚’æ¢ã™", type="primary", key="biyou_search"):
            search_params = {
                'shikaku_flg': selected_license
            }
            
            # éƒ½é“åºœçœŒãŒé¸æŠã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿è¿½åŠ 
            if selected_prefecture:
                search_params['ken_cd'] = selected_prefecture
            
            # ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ãŒãƒã‚§ãƒƒã‚¯ã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«è¿½åŠ 
            if biyou_geka:
                search_params['biyogeka_flg'] = '1'
            if biyou_hifuka:
                search_params['biyohifu_flg'] = '1'
            
            with st.spinner("æ±‚äººæƒ…å ±ã‚’å–å¾—ä¸­... ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„"):
                results = self.scrape_jobs(search_params, max_jobs, get_details)
                return results
        
        return None
    
    def scrape_jobs(self, search_params, max_jobs, get_details=False):
        """æ±‚äººæƒ…å ±ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°"""
        try:
            all_jobs = []
            page_num = 1
            
            while True:
                st.info(f"ãƒšãƒ¼ã‚¸ {page_num} ã‚’å‡¦ç†ä¸­... (ç¾åœ¨ {len(all_jobs)} ä»¶å–å¾—æ¸ˆã¿)")
                
                # URLãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰
                current_params = search_params.copy()
                if page_num > 1:
                    current_params['page'] = page_num
                
                # GETãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å®Ÿè¡Œ
                url_with_params = f"{self.SEARCH_URL}?{urlencode(current_params)}"
                response = self.session.get(url_with_params)
                response.encoding = 'utf-8'
                
                if response.status_code != 200:
                    st.warning(f"ãƒšãƒ¼ã‚¸ {page_num} ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰: {response.status_code}ï¼‰")
                    break
                
                soup = BeautifulSoup(response.text, 'html.parser')
                jobs = self.extract_jobs_from_page(soup)
                
                if not jobs:
                    if page_num == 1:
                        st.info("æŒ‡å®šã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹æ±‚äººãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                    else:
                        st.info(f"ãƒšãƒ¼ã‚¸ {page_num}: æ±‚äººãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ¤œç´¢ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                    break
                
                all_jobs.extend(jobs)
                st.info(f"ãƒšãƒ¼ã‚¸ {page_num}: {len(jobs)}ä»¶ã®æ±‚äººã‚’å–å¾—")
                
                # å–å¾—ä»¶æ•°ãƒã‚§ãƒƒã‚¯
                if len(all_jobs) >= max_jobs:
                    # å–å¾—ä»¶æ•°ã‚’è¶…ãˆãŸå ´åˆã¯åˆ‡ã‚Šè©°ã‚ã‚‹
                    all_jobs = all_jobs[:max_jobs]
                    st.success(f"ç›®æ¨™ã®{max_jobs}ä»¶ã«é”ã—ã¾ã—ãŸã€‚æ¤œç´¢ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                    break
                
                # ã‚µãƒ¼ãƒãƒ¼ã¸ã®é…æ…®
                time.sleep(2)
                page_num += 1
                
                # ç„¡é™ãƒ«ãƒ¼ãƒ—é˜²æ­¢ï¼ˆæœ€å¤§50ãƒšãƒ¼ã‚¸ = 1000ä»¶ç¨‹åº¦ï¼‰
                if page_num > 50:
                    st.warning("ãƒšãƒ¼ã‚¸æ•°ãŒ50ã‚’è¶…ãˆã¾ã—ãŸã€‚å‡¦ç†ã‚’åœæ­¢ã—ã¾ã™ã€‚")
                    break
            
            if all_jobs and get_details:
                st.info("è©³ç´°æƒ…å ±ã‚’å–å¾—ä¸­...")
                all_jobs = self.enrich_with_details(all_jobs)
            
            if all_jobs:
                df = pd.DataFrame(all_jobs)
                st.success(f"åˆè¨ˆ {len(all_jobs)} ä»¶ã®æ±‚äººã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
                return df
            else:
                return pd.DataFrame()  # ç©ºã®DataFrame
                
        except requests.exceptions.RequestException as e:
            return {"error": f"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"}
        except Exception as e:
            return {"error": f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"}
    
    def extract_jobs_from_page(self, soup):
        """1ãƒšãƒ¼ã‚¸åˆ†ã®æ±‚äººæƒ…å ±ã‚’æŠ½å‡ºï¼ˆæ–°ã—ã„ãƒ˜ãƒƒãƒ€ãƒ¼é †åºå¯¾å¿œï¼‰"""
        jobs = []
        
        # æ±‚äººãƒªã‚¹ãƒˆã‚’å–å¾—ï¼ˆå®Ÿéš›ã®HTMLã‹ã‚‰ç¢ºèªæ¸ˆã¿ï¼‰
        job_list = soup.find('ul', class_='list_jobs2')
        if not job_list:
            return jobs
        
        job_items = job_list.find_all('li')
        
        for item in job_items:
            try:
                job_data = {}
                
                # ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆäº‹æ¥­å†…å®¹ã®ä¸€éƒ¨ã¨ã—ã¦ä½¿ç”¨ï¼‰
                title_elem = item.find('h2')
                title = title_elem.get_text(strip=True) if title_elem else ""
                
                # ã‚¯ãƒªãƒ‹ãƒƒã‚¯åã¨å‹¤å‹™åœ°
                clinic_elem = item.find('p', class_='clinick_name')
                if clinic_elem:
                    # åœ°åŸŸã‚’æŠ½å‡ºï¼ˆä½æ‰€ã¨ã—ã¦ä½¿ç”¨ï¼‰
                    area_elem = clinic_elem.find('span', class_='cate')
                    job_data['ä½æ‰€'] = area_elem.get_text(strip=True) if area_elem else ""
                    
                    # ã‚¯ãƒªãƒ‹ãƒƒã‚¯åã‚’æŠ½å‡ºï¼ˆæ–½è¨­åã¨ã—ã¦ä½¿ç”¨ï¼‰
                    clinic_text = clinic_elem.get_text(strip=True)
                    if area_elem:
                        area_text = area_elem.get_text(strip=True)
                        clinic_name = clinic_text.replace(area_text, '').strip()
                        job_data['æ–½è¨­å'] = clinic_name
                    else:
                        job_data['æ–½è¨­å'] = clinic_text
                else:
                    job_data['æ–½è¨­å'] = ""
                    job_data['ä½æ‰€'] = ""
                
                # Webã‚µã‚¤ãƒˆURLï¼ˆè©³ç´°ãƒšãƒ¼ã‚¸URLï¼‰
                detail_link = item.find('a', href=re.compile(r'/job/detail/'))
                if detail_link and detail_link.get('href'):
                    job_data['Webã‚µã‚¤ãƒˆURL'] = urljoin(self.BASE_URL, detail_link.get('href'))
                else:
                    job_data['Webã‚µã‚¤ãƒˆURL'] = ""
                
                # ãƒ¡ã‚¤ãƒ³ã®æ–½è¡“ï¼ˆäº‹æ¥­å†…å®¹ã®ä¸€éƒ¨ã¨ã—ã¦ä½¿ç”¨ï¼‰
                procedure_elem = item.find('dl')
                if procedure_elem:
                    dd_elem = procedure_elem.find('dd')
                    procedure = dd_elem.get_text(strip=True) if dd_elem else ""
                else:
                    procedure = ""
                
                # äº‹æ¥­å†…å®¹ï¼ˆã‚¿ã‚¤ãƒˆãƒ« + ãƒ¡ã‚¤ãƒ³ã®æ–½è¡“ï¼‰
                event_content_parts = []
                if title:
                    event_content_parts.append(title)
                if procedure:
                    event_content_parts.append(f"ä¸»ãªæ–½è¡“: {procedure}")
                job_data['äº‹æ¥­å†…å®¹'] = " | ".join(event_content_parts) if event_content_parts else ""
                
                # åˆæœŸåŒ–ï¼ˆè©³ç´°å–å¾—ã§æ›´æ–°ã•ã‚Œã‚‹ï¼‰
                job_data['ä»£è¡¨è€…å'] = ""
                job_data['é›»è©±ç•ªå·'] = ""
                job_data['ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹'] = ""
                

                
                # ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ãªã„å ´åˆã®ã¿è¿½åŠ 
                if job_data['æ–½è¨­å']:
                    jobs.append(job_data)
                
            except Exception as e:
                st.warning(f"å€‹åˆ¥æ±‚äººã®æŠ½å‡ºã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                continue
        
        return jobs 

    def enrich_with_details(self, jobs):
        """å„æ±‚äººã®è©³ç´°æƒ…å ±ã‚’å–å¾—"""
        enriched_jobs = []
        total_jobs = len(jobs)
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’åˆæœŸåŒ–
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for i, job in enumerate(jobs):
            # é€²æ—è¡¨ç¤º
            progress = (i + 1) / total_jobs
            progress_bar.progress(progress)
            
            facility_name = job.get('ã‚¯ãƒªãƒ‹ãƒƒã‚¯å', 'N/A')
            status_text.info(f"è©³ç´°æƒ…å ±ã‚’å–å¾—ä¸­: {i+1}/{total_jobs} ({progress*100:.1f}%) - {facility_name}")
            
            # è©³ç´°ãƒšãƒ¼ã‚¸ã‹ã‚‰æƒ…å ±ã‚’å–å¾—
            detail_info = self.get_job_details(job.get('Webã‚µã‚¤ãƒˆURL', ''))
            
            # Webæ¤œç´¢ã§é€£çµ¡å…ˆæƒ…å ±ã‚’å–å¾—ï¼ˆé›»è©±ç•ªå·ãƒ»ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãŒç©ºã®å ´åˆã®ã¿ï¼‰
            facility_name = detail_info.get('æ–½è¨­å') or job.get('æ–½è¨­å', '')
            if facility_name and (not detail_info.get('é›»è©±ç•ªå·') or not detail_info.get('ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹')):
                try:
                    contact_info = self.search_contact_info_advanced(facility_name)
                    # ç©ºã®é …ç›®ã®ã¿æ›´æ–°
                    if not detail_info.get('é›»è©±ç•ªå·') and contact_info.get('é›»è©±ç•ªå·'):
                        detail_info['é›»è©±ç•ªå·'] = contact_info['é›»è©±ç•ªå·']
                    if not detail_info.get('ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹') and contact_info.get('ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹'):
                        detail_info['ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹'] = contact_info['ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹']
                except:
                    # ã‚¨ãƒ©ãƒ¼æ™‚ã¯åŸºæœ¬çš„ãªé€£çµ¡å…ˆæ¤œç´¢ã‚’ä½¿ç”¨
                    contact_info = self.search_contact_info(facility_name)
                    if not detail_info.get('é›»è©±ç•ªå·') and contact_info.get('é›»è©±ç•ªå·'):
                        detail_info['é›»è©±ç•ªå·'] = contact_info['é›»è©±ç•ªå·']
                    if not detail_info.get('ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹') and contact_info.get('ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹'):
                        detail_info['ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹'] = contact_info['ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹']
            
            # å…ƒã®æ±‚äººæƒ…å ±ã¨è©³ç´°æƒ…å ±ã‚’çµ±åˆ
            job.update(detail_info)
            enriched_jobs.append(job)
            
            # ã‚µãƒ¼ãƒãƒ¼ã¸ã®é…æ…®ï¼ˆ100ä»¶å¯¾å¿œã®ãŸã‚çŸ­ç¸®ï¼‰
            if len(jobs) <= 20:
                time.sleep(3)  # 20ä»¶ä»¥ä¸‹ã¯ä¸å¯§ã«
            elif len(jobs) <= 50:
                time.sleep(2)  # 50ä»¶ä»¥ä¸‹ã¯é€šå¸¸
            else:
                time.sleep(1.5)  # 100ä»¶ã®å ´åˆã¯åŠ¹ç‡é‡è¦–
        
        # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        progress_bar.progress(1.0)
        status_text.success(f"âœ… è©³ç´°æƒ…å ±å–å¾—å®Œäº†: {total_jobs}ä»¶ã™ã¹ã¦å‡¦ç†ã—ã¾ã—ãŸ")
        
        return enriched_jobs

    def get_job_details(self, detail_url):
        """è©³ç´°ãƒšãƒ¼ã‚¸ã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡ºï¼ˆæ–°ã—ã„ãƒ˜ãƒƒãƒ€ãƒ¼é †åºå¯¾å¿œï¼‰"""
        detail_info = {
            'æ–½è¨­å': '',
            'ä»£è¡¨è€…å': '',
            'ä½æ‰€': '',
            'Webã‚µã‚¤ãƒˆURL': '',
            'é›»è©±ç•ªå·': '',
            'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹': '',
            'äº‹æ¥­å†…å®¹': ''
        }
        
        if not detail_url:
            return detail_info
        
        try:
            response = self.session.get(detail_url)
            response.encoding = 'utf-8'
            
            if response.status_code != 200:
                return detail_info
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # æ–½è¨­åã‚’å–å¾—
            clinic_name_elem = soup.find('p', class_='clinick_name')
            if clinic_name_elem:
                # span.cateã®å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆãŒæ–½è¨­å
                area_elem = clinic_name_elem.find('span', class_='cate')
                if area_elem:
                    clinic_text = clinic_name_elem.get_text(strip=True)
                    area_text = area_elem.get_text(strip=True)
                    detail_info['æ–½è¨­å'] = clinic_text.replace(area_text, '').strip()
                else:
                    detail_info['æ–½è¨­å'] = clinic_name_elem.get_text(strip=True)
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰è©³ç´°æƒ…å ±ã‚’å–å¾—
            table = soup.find('table', class_='job_detail_tbl01')
            if table:
                rows = table.find_all('tr')
                for row in rows:
                    th = row.find('th')
                    td = row.find('td')
                    if th and td:
                        header = th.get_text(strip=True)
                        value = td.get_text(strip=True)
                        
                        if header == 'é™¢å':
                            detail_info['æ–½è¨­å'] = value
                        elif header == 'å‹¤å‹™å…ˆä½æ‰€':
                            detail_info['ä½æ‰€'] = value
                        elif header == 'ä»£è¡¨è€…' or header == 'é™¢é•·' or header == 'ç†äº‹é•·':
                            detail_info['ä»£è¡¨è€…å'] = value
                        elif header == 'é›»è©±ç•ªå·' or header == 'TEL':
                            detail_info['é›»è©±ç•ªå·'] = value
                        elif header == 'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹' or header == 'Email':
                            detail_info['ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹'] = value
            
            # Webã‚µã‚¤ãƒˆURLã¯è©³ç´°ãƒšãƒ¼ã‚¸è‡ªä½“ã®URL
            detail_info['Webã‚µã‚¤ãƒˆURL'] = detail_url
            
            # äº‹æ¥­å†…å®¹ã‚’å–å¾—ï¼ˆä»•äº‹ã®å†…å®¹ï¼‰
            job_desc_div = soup.find('div', class_='job_desc_txt')
            if job_desc_div:
                desc_p = job_desc_div.find('p')
                if desc_p:
                    detail_info['äº‹æ¥­å†…å®¹'] = desc_p.get_text(strip=True)[:500] + "..."  # 500æ–‡å­—ã«åˆ¶é™
            
            return detail_info
            
        except Exception as e:
            st.warning(f"è©³ç´°ãƒšãƒ¼ã‚¸ã®å–å¾—ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            return detail_info

    def search_contact_info(self, facility_name):
        """Webæ¤œç´¢ã§æ–½è¨­ã®é€£çµ¡å…ˆæƒ…å ±ã‚’å–å¾—ï¼ˆæ‹¡å……ç‰ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼‰"""
        contact_info = {
            'é›»è©±ç•ªå·': '',
            'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹': ''
        }
        
        try:
            # æ‹¡å……ã•ã‚ŒãŸæ—¢çŸ¥ã‚¯ãƒªãƒ‹ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
            clinic_database = {
                # å¤§æ‰‹ç¾å®¹ã‚¯ãƒªãƒ‹ãƒƒã‚¯
                "æ¹˜å—ç¾å®¹": {"é›»è©±ç•ªå·": "0120-5489-40", "ãƒ¡ãƒ¼ãƒ«": ""},
                "å“å·ç¾å®¹": {"é›»è©±ç•ªå·": "0120-189-900", "ãƒ¡ãƒ¼ãƒ«": ""},
                "TCB": {"é›»è©±ç•ªå·": "0120-86-7000", "ãƒ¡ãƒ¼ãƒ«": ""},
                "æ±äº¬ä¸­å¤®ç¾å®¹": {"é›»è©±ç•ªå·": "0120-86-7000", "ãƒ¡ãƒ¼ãƒ«": ""},
                "è–å¿ƒç¾å®¹": {"é›»è©±ç•ªå·": "0120-911-935", "ãƒ¡ãƒ¼ãƒ«": ""},
                "åŸæœ¬ã‚¯ãƒªãƒ‹ãƒƒã‚¯": {"é›»è©±ç•ªå·": "0120-107-929", "ãƒ¡ãƒ¼ãƒ«": ""},
                "æ±äº¬ç¾å®¹å¤–ç§‘": {"é›»è©±ç•ªå·": "0120-658-958", "ãƒ¡ãƒ¼ãƒ«": ""},
                "ãƒªã‚¼ã‚¯ãƒªãƒ‹ãƒƒã‚¯": {"é›»è©±ç•ªå·": "0120-966-120", "ãƒ¡ãƒ¼ãƒ«": ""},
                "ãƒ•ãƒ¬ã‚¤ã‚¢ã‚¯ãƒªãƒ‹ãƒƒã‚¯": {"é›»è©±ç•ªå·": "0120-532-888", "ãƒ¡ãƒ¼ãƒ«": ""},
                "ã‚¨ãƒŸãƒŠãƒ«ã‚¯ãƒªãƒ‹ãƒƒã‚¯": {"é›»è©±ç•ªå·": "0120-133-786", "ãƒ¡ãƒ¼ãƒ«": ""},
                "ã‚¢ãƒªã‚·ã‚¢ã‚¯ãƒªãƒ‹ãƒƒã‚¯": {"é›»è©±ç•ªå·": "0120-225-677", "ãƒ¡ãƒ¼ãƒ«": ""},
                "ãƒ¬ã‚¸ãƒ¼ãƒŠã‚¯ãƒªãƒ‹ãƒƒã‚¯": {"é›»è©±ç•ªå·": "0120-966-120", "ãƒ¡ãƒ¼ãƒ«": ""},
                "ã‚¬ãƒ¼ãƒ‡ãƒ³ã‚¯ãƒªãƒ‹ãƒƒã‚¯": {"é›»è©±ç•ªå·": "0800-813-9290", "ãƒ¡ãƒ¼ãƒ«": ""},
                "æ°´ã®æ£®ç¾å®¹å¤–ç§‘": {"é›»è©±ç•ªå·": "0120-248-603", "ãƒ¡ãƒ¼ãƒ«": ""},
                "ã‚‚ã¨ã³ç¾å®¹å¤–ç§‘": {"é›»è©±ç•ªå·": "0120-19-6102", "ãƒ¡ãƒ¼ãƒ«": ""},
                "TAã‚¯ãƒªãƒ‹ãƒƒã‚¯": {"é›»è©±ç•ªå·": "0120-229-239", "ãƒ¡ãƒ¼ãƒ«": ""},
                "å¤§å¡šç¾å®¹å½¢æˆå¤–ç§‘": {"é›»è©±ç•ªå·": "0800-888-1611", "ãƒ¡ãƒ¼ãƒ«": ""},
                "é«˜é ˆã‚¯ãƒªãƒ‹ãƒƒã‚¯": {"é›»è©±ç•ªå·": "0120-5587-10", "ãƒ¡ãƒ¼ãƒ«": ""},
                "S.T style clinic": {"é›»è©±ç•ªå·": "0120-878-135", "ãƒ¡ãƒ¼ãƒ«": ""},
                "æ¸‹è°·ç¾å®¹å¤–ç§‘": {"é›»è©±ç•ªå·": "0120-96-3720", "ãƒ¡ãƒ¼ãƒ«": ""},
                "æ–°å®¿ç¾å®¹å¤–ç§‘": {"é›»è©±ç•ªå·": "0120-4390-19", "ãƒ¡ãƒ¼ãƒ«": ""},
                "éŠ€åº§ç¾å®¹å¤–ç§‘": {"é›»è©±ç•ªå·": "0120-176-800", "ãƒ¡ãƒ¼ãƒ«": ""},
                "è¡¨å‚é“ç¾å®¹å¤–ç§‘": {"é›»è©±ç•ªå·": "0120-107-929", "ãƒ¡ãƒ¼ãƒ«": ""},
                "é’å±±ç¾å®¹å¤–ç§‘": {"é›»è©±ç•ªå·": "0120-977-278", "ãƒ¡ãƒ¼ãƒ«": ""},
                "å…­æœ¬æœ¨ç¾å®¹å¤–ç§‘": {"é›»è©±ç•ªå·": "0120-383-804", "ãƒ¡ãƒ¼ãƒ«": ""},
                # çš®è†šç§‘ãƒ»ç¾å®¹çš®è†šç§‘
                "ã‚´ãƒªãƒ©ã‚¯ãƒªãƒ‹ãƒƒã‚¯": {"é›»è©±ç•ªå·": "0120-987-118", "ãƒ¡ãƒ¼ãƒ«": ""},
                "ãƒ¡ãƒ³ã‚ºãƒªã‚¼": {"é›»è©±ç•ªå·": "0120-966-120", "ãƒ¡ãƒ¼ãƒ«": ""},
                "æ¹˜å—ç¾å®¹çš®è†šç§‘": {"é›»è©±ç•ªå·": "0120-5489-40", "ãƒ¡ãƒ¼ãƒ«": ""},
                "ã‚·ãƒ­ãƒã‚¯ãƒªãƒ‹ãƒƒã‚¯": {"é›»è©±ç•ªå·": "0800-222-1112", "ãƒ¡ãƒ¼ãƒ«": ""},
                "éŠ€åº§ã‚±ã‚¤ã‚¹ã‚­ãƒ³ã‚¯ãƒªãƒ‹ãƒƒã‚¯": {"é›»è©±ç•ªå·": "03-6228-6617", "ãƒ¡ãƒ¼ãƒ«": ""},
            }
            
            # æ–½è¨­åã‹ã‚‰å®Œå…¨ä¸€è‡´ã¾ãŸã¯éƒ¨åˆ†ä¸€è‡´ã§æ¤œç´¢
            for clinic_key, clinic_info in clinic_database.items():
                if clinic_key in facility_name:
                    contact_info['é›»è©±ç•ªå·'] = clinic_info["é›»è©±ç•ªå·"]
                    if clinic_info["ãƒ¡ãƒ¼ãƒ«"]:
                        contact_info['ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹'] = clinic_info["ãƒ¡ãƒ¼ãƒ«"]
                    st.success(f"âœ… {facility_name} ã®é€£çµ¡å…ˆæƒ…å ±ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ã—ã¾ã—ãŸ")
                    return contact_info
            
            # åœ°åŸŸåˆ¥ã®ä¸€èˆ¬çš„ãªé€£çµ¡å…ˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿæˆ
            if any(keyword in facility_name for keyword in ["ã‚¯ãƒªãƒ‹ãƒƒã‚¯", "ç¾å®¹", "çš®è†šç§‘", "å½¢æˆå¤–ç§‘"]):
                # åœ°åŸŸã‚’åˆ¤å®šã—ã¦ä»£è¡¨çš„ãªé›»è©±ç•ªå·å½¢å¼ã‚’ææ¡ˆ
                if any(area in facility_name for area in ["æ–°å®¿", "æ¸‹è°·", "æ± è¢‹", "éŠ€åº§", "è¡¨å‚é“", "å…­æœ¬æœ¨", "æµæ¯”å¯¿"]):
                    st.info(f"ğŸ’¡ æ±äº¬éƒ½å†…ã®{facility_name}ã§ã™ã€‚è©³ç´°ãªé€£çµ¡å…ˆã¯ç›´æ¥ã‚¯ãƒªãƒ‹ãƒƒã‚¯ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„")
                elif any(area in facility_name for area in ["æ¨ªæµœ", "å·å´", "è—¤æ²¢", "åšæœ¨"]):
                    st.info(f"ğŸ’¡ ç¥å¥ˆå·çœŒã®{facility_name}ã§ã™ã€‚è©³ç´°ãªé€£çµ¡å…ˆã¯ç›´æ¥ã‚¯ãƒªãƒ‹ãƒƒã‚¯ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„")
                else:
                    st.info(f"ğŸ’¡ {facility_name} ã®è©³ç´°ãªé€£çµ¡å…ˆæƒ…å ±ã¯ç›´æ¥ã‚¯ãƒªãƒ‹ãƒƒã‚¯ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„")
            
            return contact_info
            
        except Exception as e:
            st.warning(f"é€£çµ¡å…ˆæ¤œç´¢ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            return contact_info

    def search_contact_info_advanced(self, facility_name):
        """Webæ¤œç´¢APIã‚’ä½¿ç”¨ã—ã¦æ–½è¨­ã®é€£çµ¡å…ˆæƒ…å ±ã‚’å–å¾—"""
        contact_info = {
            'é›»è©±ç•ªå·': '',
            'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹': ''
        }
        
        # æ—¢çŸ¥ã®ã‚¯ãƒªãƒ‹ãƒƒã‚¯æƒ…å ±ã‚’å„ªå…ˆ
        basic_info = self.search_contact_info(facility_name)
        if basic_info['é›»è©±ç•ªå·']:
            return basic_info
        
        try:
            # å®Ÿéš›ã®Webæ¤œç´¢ã‚’å®Ÿè¡Œ
            search_query = f"{facility_name} é›»è©±ç•ªå· é€£çµ¡å…ˆ"
            
            st.info(f"ğŸ” {facility_name} ã®é€£çµ¡å…ˆã‚’æ¤œç´¢ä¸­...")
            
            # perform_web_searchãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¦æ¤œç´¢ã‚’å®Ÿè¡Œ
            result_text = self.perform_web_search(search_query)
            
            if result_text:
                # æ¤œç´¢çµæœã‹ã‚‰é›»è©±ç•ªå·ã‚’æŠ½å‡º
                # é›»è©±ç•ªå·ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
                phone_patterns = [
                    r'(0120[-â€\s]?\d{2,3}[-â€\s]?\d{3,4})',     # ãƒ•ãƒªãƒ¼ãƒ€ã‚¤ãƒ¤ãƒ«
                    r'(\d{2,4}[-â€\s]?\d{2,4}[-â€\s]?\d{3,4})',  # ä¸€èˆ¬çš„ãªé›»è©±ç•ªå·
                    r'(\d{3}[-â€\s]?\d{3}[-â€\s]?\d{4})'        # 3-3-4å½¢å¼
                ]
                
                for pattern in phone_patterns:
                    matches = re.findall(pattern, result_text)
                    if matches:
                        # æœ€åˆã«è¦‹ã¤ã‹ã£ãŸé›»è©±ç•ªå·ã‚’ä½¿ç”¨
                        phone_number = matches[0]
                        # æ•´å½¢
                        if isinstance(phone_number, tuple):
                            phone_number = phone_number[0] if phone_number[0] else matches[0]
                        contact_info['é›»è©±ç•ªå·'] = phone_number.replace(' ', '-')
                        break
                
                # ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
                email_pattern = r'[\w\.-]+@[\w\.-]+\.\w+'
                email_matches = re.findall(email_pattern, result_text)
                
                if email_matches:
                    # ä¸€èˆ¬çš„ãªãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’é™¤å¤–
                    valid_emails = [email for email in email_matches 
                                  if not any(skip in email.lower() for skip in 
                                           ['google', 'youtube', 'facebook', 'twitter', 'example', 'noreply', 'duckduckgo'])]
                    if valid_emails:
                        contact_info['ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹'] = valid_emails[0]
                
                if contact_info['é›»è©±ç•ªå·'] or contact_info['ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹']:
                    st.success(f"âœ… {facility_name} ã®é€£çµ¡å…ˆæƒ…å ±ã‚’å–å¾—ã—ã¾ã—ãŸ")
                else:
                    st.warning(f"âš ï¸ {facility_name} ã®é€£çµ¡å…ˆæƒ…å ±ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            else:
                st.warning(f"âš ï¸ {facility_name} ã®æ¤œç´¢çµæœãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            
            return contact_info
            
        except Exception as e:
            st.warning(f"Webæ¤œç´¢ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            return self.search_contact_info(facility_name)

    def perform_web_search(self, search_term):
        """Webæ¤œç´¢ã‚’å®Ÿè¡Œã™ã‚‹ï¼ˆè¤‡æ•°æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³å¯¾å¿œãƒ»ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ä»˜ãï¼‰"""
        try:
            # ç’°å¢ƒåˆ¤å®šï¼ˆStreamlit Cloudç’°å¢ƒã®æ¤œå‡ºï¼‰
            import os
            import platform
            
            # ã‚ˆã‚Šæ­£ç¢ºãªã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒæ¤œå‡º
            cloud_indicators = [
                'STREAMLIT_CLOUD',
                'STREAMLIT_SHARING_MODE', 
                'HOSTNAME' in os.environ and 'streamlit' in os.environ.get('HOSTNAME', '').lower(),
                platform.node() and 'streamlit' in platform.node().lower(),
                'USER' in os.environ and os.environ.get('USER') == 'appuser',
                'HOME' in os.environ and '/home/appuser' in os.environ.get('HOME', ''),
                'STREAMLIT_SERVER_HEADLESS' in os.environ
            ]
            
            is_cloud_env = any(cloud_indicators)
            
            if is_cloud_env:
                st.warning("âš ï¸ ã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒã§ã¯Webæ¤œç´¢æ©Ÿèƒ½ãŒåˆ¶é™ã•ã‚Œã¦ã„ã¾ã™ã€‚æ—¢çŸ¥ã®ã‚¯ãƒªãƒ‹ãƒƒã‚¯æƒ…å ±ã®ã¿æä¾›ã—ã¾ã™ã€‚")
                
                # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã®ã¿è¡¨ç¤ºï¼‰
                if st.session_state.get('biyou_debug', False):
                    with st.expander("ğŸ”§ ç’°å¢ƒãƒ‡ãƒãƒƒã‚°æƒ…å ±"):
                        st.code(f"""
ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯:
- STREAMLIT_CLOUD: {os.environ.get('STREAMLIT_CLOUD', 'Not set')}
- STREAMLIT_SHARING_MODE: {os.environ.get('STREAMLIT_SHARING_MODE', 'Not set')}
- HOSTNAME: {os.environ.get('HOSTNAME', 'Not set')}
- USER: {os.environ.get('USER', 'Not set')}
- HOME: {os.environ.get('HOME', 'Not set')}
- Platform node: {platform.node()}
- Cloud indicators: {cloud_indicators}
                        """)
                
                return ""
            
            # æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®ãƒªã‚¹ãƒˆï¼ˆå„ªå…ˆé †ä½é †ï¼‰
            search_engines = [
                {
                    'name': 'DuckDuckGo Instant',
                    'url': f"https://api.duckduckgo.com/?q={requests.utils.quote(search_term)}&format=json&no_html=1",
                    'method': 'api'
                },
                {
                    'name': 'DuckDuckGo HTML',
                    'url': f"https://html.duckduckgo.com/html/?q={requests.utils.quote(search_term)}",
                    'method': 'html'
                },
                {
                    'name': 'Bing',
                    'url': f"https://www.bing.com/search?q={requests.utils.quote(search_term)}",
                    'method': 'html'
                }
            ]
            
            # User-Agentã‚’å¼·åŒ–
            headers = {
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'ja,en-US;q=0.5',
                'Accept-Encoding': 'gzip, deflate',
                'DNT': '1',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1'
            }
            
            for engine in search_engines:
                try:
                    st.info(f"ğŸ” {engine['name']}ã§æ¤œç´¢ä¸­...")
                    
                    if engine['method'] == 'api':
                        # DuckDuckGo APIã‚’ä½¿ç”¨
                        response = requests.get(engine['url'], headers=headers, timeout=15)
                        if response.status_code == 200:
                            data = response.json()
                            if 'AbstractText' in data and data['AbstractText']:
                                return data['AbstractText']
                            elif 'Answer' in data and data['Answer']:
                                return data['Answer']
                    
                    elif engine['method'] == 'html':
                        # HTMLè§£æ
                        response = requests.get(engine['url'], headers=headers, timeout=15)
                        if response.status_code == 200:
                            soup = BeautifulSoup(response.text, 'html.parser')
                            
                            results = []
                            
                            if 'duckduckgo' in engine['url']:
                                # DuckDuckGo HTMLçµæœã®è§£æ
                                result_elements = soup.find_all(['h2', 'span'], class_=lambda x: x and 'result' in str(x))
                                snippet_elements = soup.find_all('a', class_='result__snippet')
                                
                                for elem in result_elements[:3]:
                                    text = elem.get_text(strip=True)
                                    if text and len(text) > 10:
                                        results.append(text)
                                
                                for elem in snippet_elements[:3]:
                                    text = elem.get_text(strip=True)
                                    if text and len(text) > 10:
                                        results.append(text)
                            
                            elif 'bing' in engine['url']:
                                # Bingçµæœã®è§£æ
                                result_elements = soup.find_all('h2')
                                snippet_elements = soup.find_all('p')
                                
                                for elem in result_elements[:3]:
                                    text = elem.get_text(strip=True)
                                    if text and len(text) > 10:
                                        results.append(text)
                                
                                for elem in snippet_elements[:3]:
                                    text = elem.get_text(strip=True)
                                    if text and len(text) > 20:
                                        results.append(text)
                            
                            if results:
                                st.success(f"âœ… {engine['name']}ã‹ã‚‰æƒ…å ±ã‚’å–å¾—ã—ã¾ã—ãŸ")
                                return " ".join(results[:5])  # ä¸Šä½5ä»¶ã¾ã§
                    
                    # å„ã‚¨ãƒ³ã‚¸ãƒ³ã®é–“ã«å°‘ã—å¾…æ©Ÿ
                    time.sleep(2)
                    
                except requests.exceptions.RequestException as e:
                    st.warning(f"âš ï¸ {engine['name']}ã¸ã®æ¥ç¶šã«å¤±æ•—: {str(e)}")
                    continue
                except Exception as e:
                    st.warning(f"âš ï¸ {engine['name']}ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    continue
            
            # ã™ã¹ã¦ã®æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ãŒå¤±æ•—ã—ãŸå ´åˆ
            st.warning("âš ï¸ ã™ã¹ã¦ã®æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‹ã‚‰ã®æƒ…å ±å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return ""
            
        except Exception as e:
            st.warning(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return "" 